{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c9764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All data loaded successfully. Ready for model training!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "X_train_sm = joblib.load('Data/X_train_sm.pkl')\n",
    "y_train_sm = joblib.load('Data/y_train_sm.pkl')\n",
    "X_test = joblib.load('Data/X_test.pkl')\n",
    "y_test = joblib.load('Data/y_test.pkl')\n",
    "print(\" All data loaded successfully. Ready for model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885da93",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad16638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logistic Regression Model Evaluation\n",
      "\n",
      "Accuracy: 0.9515\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17861   433]\n",
      " [  536  1164]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.976     0.974     18294\n",
      "           1      0.729     0.685     0.706      1700\n",
      "\n",
      "    accuracy                          0.952     19994\n",
      "   macro avg      0.850     0.831     0.840     19994\n",
      "weighted avg      0.950     0.952     0.951     19994\n",
      "\n",
      "ROC-AUC Score: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tamma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train_sm, y_train_sm)\n",
    "y_pred = log_model.predict(X_test)\n",
    "y_pred_proba = log_model.predict_proba(X_test)[:, 1]  # probability for ROC curve\n",
    "print(\"Logistic Regression Model Evaluation\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee259a2",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f80340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random Forest Model Evaluation\n",
      "\n",
      "Accuracy: 0.9705\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18236    58]\n",
      " [  532  1168]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.997     0.984     18294\n",
      "           1      0.953     0.687     0.798      1700\n",
      "\n",
      "    accuracy                          0.970     19994\n",
      "   macro avg      0.962     0.842     0.891     19994\n",
      "weighted avg      0.970     0.970     0.968     19994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,       # number of trees (you can tune this)\n",
    "    max_depth=None,         # let trees expand fully\n",
    "    random_state=42,\n",
    "    n_jobs=-1               # use all CPU cores for speed\n",
    ")\n",
    "rf_model.fit(X_train_sm, y_train_sm)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\" Random Forest Model Evaluation\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a420811f",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17621cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Naive Bayes Model Evaluation\n",
      "\n",
      "Accuracy: 0.9040\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17368   926]\n",
      " [  994   706]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.946     0.949     0.948     18294\n",
      "           1      0.433     0.415     0.424      1700\n",
      "\n",
      "    accuracy                          0.904     19994\n",
      "   macro avg      0.689     0.682     0.686     19994\n",
      "weighted avg      0.902     0.904     0.903     19994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_sm, y_train_sm)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\" Naive Bayes Model Evaluation\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92179349",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 73174, number of negative: 73174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 938\n",
      "[LightGBM] [Info] Number of data points in the train set: 146348, number of used features: 72\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "âœ… LightGBM Model Evaluation\n",
      "\n",
      "Accuracy: 0.9715\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18251    43]\n",
      " [  526  1174]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.998     0.985     18294\n",
      "           1      0.965     0.691     0.805      1700\n",
      "\n",
      "    accuracy                          0.972     19994\n",
      "   macro avg      0.968     0.844     0.895     19994\n",
      "weighted avg      0.971     0.972     0.969     19994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "X_train_sm.columns = X_train_sm.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "X_test.columns = X_test.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "lgb_model = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lgb_model.fit(X_train_sm, y_train_sm)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "print(\" LightGBM Model Evaluation\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lgb):.4f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_lgb)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lgb, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce708d",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87584038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tamma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [08:46:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… XGBoost Model Evaluation\n",
      "\n",
      "Accuracy: 0.9716\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18254    40]\n",
      " [  528  1172]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.998     0.985     18294\n",
      "           1      0.967     0.689     0.805      1700\n",
      "\n",
      "    accuracy                          0.972     19994\n",
      "   macro avg      0.969     0.844     0.895     19994\n",
      "weighted avg      0.971     0.972     0.969     19994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "X_train_sm.columns = X_train_sm.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "X_test.columns = X_test.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,         # number of boosting rounds\n",
    "    learning_rate=0.05,       # step size shrinkage\n",
    "    max_depth=6,              # tree depth\n",
    "    subsample=0.8,            # row sampling\n",
    "    colsample_bytree=0.8,     # column sampling\n",
    "    random_state=42,\n",
    "    n_jobs=-1,                # use all CPU cores\n",
    "    use_label_encoder=False,  # suppress label encoding warning\n",
    "    eval_metric='logloss'     # binary classification metric\n",
    ")\n",
    "xgb_model.fit(X_train_sm, y_train_sm)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\" XGBoost Model Evaluation\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e0fd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ XGBoost model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save trained XGBoost model for reuse\n",
    "joblib.dump(xgb_model, 'Data/xgboost_model.pkl')\n",
    "print(\"ðŸ’¾ XGBoost model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
